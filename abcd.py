# -*- coding: utf-8 -*-
"""Colab'e hoÅŸ geldiniz.

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix, roc_auc_score, roc_curve
from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC, SVR
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier, XGBRegressor

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
from tensorflow.keras.optimizers import Adam

st.title("ğŸ“Š Otomatik ML & DL Model EÄŸitimi ve Tahmin UygulamasÄ±")

uploaded_file = st.file_uploader("1. AdÄ±m: CSV dosyanÄ±zÄ± yÃ¼kleyin", type=["csv"])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.success("Dosya yÃ¼klendi!")
    st.write("Veri Ã–nizlemesi:", df.head())

    st.subheader("2. AdÄ±m: Hedef (Ã§Ä±ktÄ±) sÃ¼tunu ve giriÅŸ sÃ¼tunlarÄ±")
    target_column = st.selectbox("Ã‡Ä±ktÄ± sÃ¼tunu:", df.columns)
    all_input_columns = [col for col in df.columns if col != target_column]

    numerical_columns = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical_columns = df.select_dtypes(exclude=[np.number]).columns.tolist()

    feature_num = st.multiselect("GiriÅŸ sÃ¼tunlarÄ± (SayÄ±sal):", [col for col in numerical_columns if col in all_input_columns])
    feature_cat = st.multiselect("GiriÅŸ sÃ¼tunlarÄ± (Kategori):", [col for col in categorical_columns if col in all_input_columns])

    feature_columns = feature_num + feature_cat

    if target_column and feature_columns:
        df = df.dropna(subset=[target_column] + feature_columns)
        df_processed = pd.get_dummies(df[feature_columns], drop_first=True)
        X = df_processed.values
        y = df[target_column].values

        st.success("SÃ¼tunlar baÅŸarÄ±yla seÃ§ildi.")

        st.subheader("3. AdÄ±m: Model SeÃ§imi")
        model_choice = st.selectbox("Model seÃ§in:", [
            "Logistic Regression (SÄ±nÄ±flandÄ±rma)",
            "Decision Tree (SÄ±nÄ±flandÄ±rma)",
            "Random Forest (SÄ±nÄ±flandÄ±rma)",
            "Linear Regression (Regresyon)",
            "Ridge Regression (Regresyon)",
            "Lasso Regression (Regresyon)",
            "Gradient Boosting Classifier (SÄ±nÄ±flandÄ±rma)",
            "Gradient Boosting Regressor (Regresyon)",
            "XGBoost Classifier (SÄ±nÄ±flandÄ±rma)",
            "XGBoost Regressor (Regresyon)",
            "K-Nearest Neighbors (SÄ±nÄ±flandÄ±rma)",
            "Support Vector Machine (SÄ±nÄ±flandÄ±rma)",
            "Support Vector Regressor (Regresyon)",
            "Naive Bayes (SÄ±nÄ±flandÄ±rma)",
            "Dense Neural Network (MLP) (SÄ±nÄ±flandÄ±rma)",
            "Dense Neural Network (MLP) (Regresyon)",
            "LSTM (Regresyon)"
        ])

        num_rows = df.shape[0]
        epochs = 50 if num_rows < 1000 else 30 if num_rows < 5000 else 10

        st.subheader("4. AdÄ±m: EÄŸitim AyarlarÄ±")
        st.write(f"Veri boyutuna gÃ¶re Ã¶nerilen epoch: **{epochs}**")

        if st.button("Modeli EÄŸit", type="primary"):
            model = None
            scaler = None
            is_classification = "(SÄ±nÄ±flandÄ±rma)" in model_choice

            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

            # Dtype kontrolÃ¼ ve dÃ¶nÃ¼ÅŸtÃ¼rme
            if isinstance(X_train, pd.DataFrame):
                X_train = X_train.astype(np.float32)
                X_test = X_test.astype(np.float32)
            else:
                X_train = X_train.astype(np.float32, copy=False)
                X_test = X_test.astype(np.float32, copy=False)

            if model_choice in ["Dense Neural Network (MLP) (SÄ±nÄ±flandÄ±rma)", "Dense Neural Network (MLP) (Regresyon)", "LSTM (Regresyon)"]:
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train.astype(np.float32, copy=False))
                X_test_scaled = scaler.transform(X_test.astype(np.float32, copy=False))

                if model_choice == "LSTM":
                    X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))
                    X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))
                    model = Sequential([
                        LSTM(50, input_shape=(X_train_scaled.shape[1], 1)),
                        Dense(1)
                    ])
                    model.compile(optimizer=Adam(), loss='mse')
                    history = model.fit(X_train_scaled, y_train, epochs=epochs, batch_size=32, verbose=0)
                    preds = model.predict(X_test_scaled).flatten()
                    mse = mean_squared_error(y_test, preds)
                    st.success(f"MSE (LSTM): {mse:.4f}")

                elif model_choice == "Dense Neural Network (MLP) (SÄ±nÄ±flandÄ±rma)" or model_choice == "Dense Neural Network (MLP) (Regresyon)":
                    model = Sequential([
                        Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'),
                        Dense(32, activation='relu'),
                        Dense(1, activation='sigmoid' if is_classification else 'linear')
                    ])
                    model.compile(optimizer=Adam(), loss='binary_crossentropy' if is_classification else 'mse')
                    history = model.fit(X_train_scaled, y_train, epochs=epochs, batch_size=32, verbose=0)
                    preds = model.predict(X_test_scaled).flatten()
                    if is_classification:
                        preds_class = (preds > 0.5).astype(int)
                        acc = accuracy_score(y_test, preds_class)
                        st.success(f"Accuracy (MLP): {acc:.4f}")
                    else:
                        mse = mean_squared_error(y_test, preds)
                        st.success(f"MSE (MLP): {mse:.4f}")

            else:
                if model_choice == "Logistic Regression (SÄ±nÄ±flandÄ±rma)":
                    model = LogisticRegression(max_iter=1000)
                elif model_choice == "Decision Tree (SÄ±nÄ±flandÄ±rma)":
                    model = DecisionTreeClassifier()
                elif model_choice == "Random Forest (SÄ±nÄ±flandÄ±rma)":
                    model = RandomForestClassifier()
                elif model_choice == "Linear Regression (Regresyon)":
                    model = LinearRegression()
                elif model_choice == "Ridge Regression (Regresyon)":
                    model = Ridge()
                elif model_choice == "Lasso Regression (Regresyon)":
                    model = Lasso()
                elif model_choice == "Gradient Boosting Classifier (SÄ±nÄ±flandÄ±rma)":
                    model = GradientBoostingClassifier()
                elif model_choice == "Gradient Boosting Regressor (Regresyon)":
                    model = GradientBoostingRegressor()
                elif model_choice == "XGBoost Classifier (SÄ±nÄ±flandÄ±rma)":
                    model = XGBClassifier(eval_metric='logloss')
                elif model_choice == "XGBoost Regressor (Regresyon)":
                    model = XGBRegressor()
                elif model_choice == "K-Nearest Neighbors (SÄ±nÄ±flandÄ±rma)":
                    model = KNeighborsClassifier()
                elif model_choice == "Support Vector Machine (SÄ±nÄ±flandÄ±rma)":
                    model = SVC(probability=True)
                elif model_choice == "Support Vector Regressor (Regresyon)":
                    model = SVR()
                elif model_choice == "Naive Bayes (SÄ±nÄ±flandÄ±rma)":
                    model = GaussianNB()

                X_train = X_train.astype(np.float32, copy=False)
                y_train = y_train.astype(np.float32, copy=False) if not is_classification else y_train
                model.fit(X_train, y_train)
                X_test = X_test.astype(np.float32, copy=False)
                preds = model.predict(X_test)

                if is_classification:
                    acc = accuracy_score(y_test, preds)
                    st.success(f"Accuracy ({model_choice}): {acc:.4f}")
                    cm = confusion_matrix(y_test, preds)
                    st.subheader("Confusion Matrix")
                    st.dataframe(pd.DataFrame(cm))
                else:
                    mse = mean_squared_error(y_test, preds)
                    st.success(f"MSE ({model_choice}): {mse:.4f}")

            st.subheader("ğŸ“ˆ EÄŸitim / Test BaÅŸarÄ±mÄ±")
            if not is_classification:
                if scaler is not None:
                    y_train_pred = model.predict(X_train_scaled).flatten()
                    y_test_pred = model.predict(X_test_scaled).flatten()
                else:
                    y_train_pred = model.predict(X_train).flatten()
                    y_test_pred = model.predict(X_test).flatten()
                st.write(f"EÄŸitim MSE: {mean_squared_error(y_train, y_train_pred):.4f}")
                st.write(f"Test MSE: {mean_squared_error(y_test, y_test_pred):.4f}")
            else:
                y_train_pred = model.predict(X_train)
                if isinstance(y_train_pred[0], np.ndarray) or np.issubdtype(y_train_pred.dtype, np.floating):
                    y_train_pred = (y_train_pred > 0.5).astype(int)

                y_test_pred = model.predict(X_test)
                if isinstance(y_test_pred[0], np.ndarray) or np.issubdtype(y_test_pred.dtype, np.floating):
                    y_test_pred = (y_test_pred > 0.5).astype(int)

                st.write(f"EÄŸitim Accuracy: {accuracy_score(y_train, y_train_pred):.4f}")
                st.write(f"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}")

            st.subheader("ğŸ” Ã–zellik DaÄŸÄ±lÄ±mlarÄ±")
            for col in feature_num[:3]:
                fig_feat, ax_feat = plt.subplots()
                sns.histplot(df[col], bins=20, kde=True, ax=ax_feat)
                ax_feat.set_title(f"{col} DaÄŸÄ±lÄ±mÄ±")
                st.pyplot(fig_feat)

            st.session_state.model = model
            st.session_state.model_type = model_choice
            st.session_state.scaler = scaler
            st.session_state.feature_columns = df_processed.columns.tolist()
            st.session_state.is_trained = True

        if "is_trained" in st.session_state and st.session_state.is_trained:
            st.subheader("ğŸ§ª Tahmin Paneli")
            input_data = {}

            # SayÄ±sal giriÅŸler
            st.markdown("### ğŸ“Œ SayÄ±sal Girdiler")
            for feature in feature_num:
                input_val = st.number_input(f"{feature}", key=f"input_{feature}")
                input_data[feature] = input_val

            # Kategorik giriÅŸler
            if feature_cat:
                cat_cols_used = []
                for cat in feature_cat:
                    if cat in df.columns:
                        for val in df[cat].dropna().unique():
                            col_name = f"{cat}_{val}"
                            if col_name in st.session_state.feature_columns:
                                cat_cols_used.append((cat, val))

                if cat_cols_used:
                    st.markdown("### ğŸ·ï¸ Kategorik Girdiler")
                    for cat_feature in set(cat for cat, _ in cat_cols_used):
                        options = df[cat_feature].dropna().unique().tolist()
                        selected = st.selectbox(f"{cat_feature} seÃ§imi", options=options, key=f"select_{cat_feature}")
                        for val in df[cat_feature].dropna().unique():
                            col_name = f"{cat_feature}_{val}"
                            input_data[col_name] = 1 if val == selected else 0

            # Eksik one-hot sÃ¼tunlarÄ± 0'la doldur
            for col in st.session_state.feature_columns:
                if col not in input_data:
                    input_data[col] = 0

            if st.button("Tahmin Yap"):
                input_df = pd.DataFrame([input_data])[st.session_state.feature_columns].astype(np.float32)
                model = st.session_state.model
                model_choice = st.session_state.model_type
                scaler = st.session_state.get("scaler", None)

                if model_choice in ["Dense Neural Network (MLP)", "LSTM"]:
                    input_scaled = scaler.transform(input_df)
                    if model_choice == "LSTM":
                        input_scaled = input_scaled.reshape((1, input_scaled.shape[1], 1))
                    prediction = model.predict(input_scaled).flatten()[0]
                else:
                    prediction = model.predict(input_df)[0]

                if model_choice in ["Logistic Regression (SÄ±nÄ±flandÄ±rma)", "Decision Tree (SÄ±nÄ±flandÄ±rma)", "Random Forest (SÄ±nÄ±flandÄ±rma)", "Gradient Boosting Classifier (SÄ±nÄ±flandÄ±rma)", "XGBoost Classifier (SÄ±nÄ±flandÄ±rma)", "K-Nearest Neighbors (SÄ±nÄ±flandÄ±rma)", "Support Vector Machine (SÄ±nÄ±flandÄ±rma)", "Naive Bayes (SÄ±nÄ±flandÄ±rma)", "Dense Neural Network (MLP) (SÄ±nÄ±flandÄ±rma)"]:
                    prediction_class = 1 if prediction > 0.5 else 0
                    st.success(f"Tahmin edilen sÄ±nÄ±f: {prediction_class} (olasÄ±lÄ±k: {float(prediction):.4f})")
                else:
                    st.success(f"Tahmin edilen deÄŸer: {prediction:.4f}")